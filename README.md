# Object Detection using CoreML
![image](https://user-images.githubusercontent.com/63160825/215057345-34a5a6a5-b3ea-451d-bbbd-7ddc859dc9fc.png)

Core ML applies a machine learning algorithm to a set of training data to create a model. You use a model to make predictions based on new input data. Models can accomplish a wide variety of tasks that would be difficult or impractical to write in code. For example, you can train a model to categorize photos, or detect specific objects within a photo directly from its pixels.
                                                                          After you create the model, integrate it in your app and deploy it on the user’s device. Your app uses Core ML APIs and user data to make predictions and to train or fine-tune the model.

![image](https://user-images.githubusercontent.com/63160825/215057785-94f6d5fa-08b1-4c9f-a8c8-8c3eb1c97420.png)

You can build and train a model with the Create ML app bundled with Xcode. Models trained using are in the Core ML model format and are ready to use in your app. Alternatively, you can use a wide variety of other machine learning libraries and then use Core ML Tools to convert the model into the Core ML format. Once a model is on a user’s device, you can use Core ML to retrain or fine-tune it on-device, with that user’s data.  
                                                                                                                            Core ML optimizes on-device performance by leveraging the CPU, GPU, and Neural Engine while minimizing its memory footprint and power consumption. Running a model strictly on the user’s device removes any need for a network connection, which helps keep the user’s data private and your app responsive.

Core ML is the foundation for domain-specific frameworks and functionality. Core ML supports Vision for analyzing images, Natural Language for processing text, Speech for converting audio to text, and Sound Analysis for identifying sounds in audio. Core ML itself builds on top of low-level primitives like Accelerate and BNNS, as well as Metal Performance Shaders.

![image](https://user-images.githubusercontent.com/63160825/215057612-e69a36f6-137f-41f4-8a01-9e033f47787a.png)

> Vision framework performs face and face landmark detection, text detection, barcode recognition, image registration, and general feature tracking. Vision also allows the use of custom Core ML models for tasks like classification or object detection.

## Project Work
Real time camera object detection with Machine Learning. Basic introduction to Core ML, Vision and ARKit.
